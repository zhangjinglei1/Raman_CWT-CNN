#!/usr/bin/env python
# coding: utf-8

# In[10]:


import os
import glob
import torch
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, accuracy_score
from torch.utils.data import DataLoader
from torchvision import transforms
from PIL import Image

# å‡è®¾ä½ å·²æœ‰ Mydatasetpro ç±»ï¼ˆæŽ¥å—å›¾åƒè·¯å¾„åˆ—è¡¨å’Œæ ‡ç­¾åˆ—è¡¨ï¼‰
from torch.utils import data
# é€šè¿‡åˆ›å»ºdata.Datasetå­ç±»Mydatasetæ¥åˆ›å»ºè¾“å…¥
class Mydataset(data.Dataset):
    # ç±»åˆå§‹åŒ–
    def __init__(self, root):
        self.imgs_path = root

    # è¿›è¡Œåˆ‡ç‰‡
    def __getitem__(self, index):
        img_path = self.imgs_path[index]
        return img_path

    # è¿”å›žé•¿åº¦
    def __len__(self):
        return len(self.imgs_path)


# å¯¹æ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.Resize((112, 224)),  # åšçš„ç¬¬ä¸€æ­¥è½¬æ¢
    transforms.ToTensor(),  # ç¬¬äºŒæ­¥è½¬æ¢ï¼Œä½œç”¨ï¼šç¬¬ä¸€è½¬æ¢æˆTensorï¼Œç¬¬äºŒå°†å›¾ç‰‡å–å€¼èŒƒå›´è½¬æ¢æˆ0-1ä¹‹é—´ï¼Œç¬¬ä¸‰ä¼šå°†channelç½®å‰
    transforms.Normalize(std=[0.229, 0.224, 0.225], mean=[0.485, 0.456, 0.406])
])


class Mydatasetpro(data.Dataset):
    # ç±»åˆå§‹åŒ–
    def __init__(self, img_paths, labels, transform):
        self.imgs = img_paths
        self.labels = labels
        self.transforms = transform

    # è¿›è¡Œåˆ‡ç‰‡
    def __getitem__(self, index):  # æ ¹æ®ç»™å‡ºçš„ç´¢å¼•è¿›è¡Œåˆ‡ç‰‡ï¼Œå¹¶å¯¹å…¶è¿›è¡Œæ•°æ®å¤„ç†è½¬æ¢æˆTensorï¼Œè¿”å›žæˆTensor
        img = self.imgs[index]
        label = self.labels[index]
        pil_img = Image.open(img)  # pip install pillow
        data = self.transforms(pil_img)
        return data, label

    # è¿”å›žé•¿åº¦
    def __len__(self):
        return len(self.imgs)

# ========================
# 1. åŠ è½½æ¨¡åž‹å’ŒåŽŸå§‹æ ‡ç­¾
# ========================
model = torch.load(r"20251223_GLN_spect_p_f_202_fl_22.pt", map_location='cpu')
model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼

# 2. å®šä¹‰å›¾åƒå˜æ¢ï¼ˆéœ€ä¸Žè®­ç»ƒæ—¶ä¸€è‡´ï¼ï¼‰
# å¯¹æ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†
transform = transforms.Compose([
                transforms.Grayscale(num_output_channels=3),
                transforms.Resize((112,224)), #åšçš„ç¬¬ä¸€æ­¥è½¬æ¢
                transforms.ToTensor(), #ç¬¬äºŒæ­¥è½¬æ¢ï¼Œä½œç”¨ï¼šç¬¬ä¸€è½¬æ¢æˆTensorï¼Œç¬¬äºŒå°†å›¾ç‰‡å–å€¼èŒƒå›´è½¬æ¢æˆ0-1ä¹‹é—´ï¼Œç¬¬ä¸‰ä¼šå°†channelç½®å‰
                #transforms.Normalize(std=(0.5,0.5,0.5),mean=(0.5,0.5,0.5))
])

# ========================
# 3. éåŽ†æ‰€æœ‰å™ªå£°å­æ–‡ä»¶å¤¹å¹¶è¯„ä¼°
# ========================
base_dir =r'cwt_images_1218val'
results_summary = {}  # å­˜å‚¨æ¯ç»„çš„å‡†ç¡®çŽ‡
original_labels=np.loadtxt("train_label1223.txt")
# è‡ªåŠ¨èŽ·å–æ‰€æœ‰ snr_XX æ–‡ä»¶å¤¹
snr_folders = [d for d in os.listdir(base_dir) if d.startswith('snr_') and os.path.isdir(os.path.join(base_dir, d))]
print(snr_folders)
for snr_folder in sorted(snr_folders):
    snr_path = os.path.join(base_dir, snr_folder)
    noise_types = [d for d in os.listdir(snr_path) if os.path.isdir(os.path.join(snr_path, d))]
    
    for noise_type in sorted(noise_types):
        print(f"\n Evaluating â†’ {snr_folder} / {noise_type}")
        
        img_dir = os.path.join(snr_path, noise_type)
        # èŽ·å–æ‰€æœ‰å›¾åƒè·¯å¾„ï¼Œå¹¶æŒ‰æ–‡ä»¶åæŽ’åºä»¥ä¿è¯é¡ºåºä¸€è‡´
        img_paths = sorted(glob.glob(os.path.join(img_dir, "sample_*.jpg")))

#         if len(img_paths) != 2560:
#             print(f"âš ï¸ è­¦å‘Š: {snr_folder}/{noise_type} ä¸­å›¾åƒæ•°é‡={len(img_paths)} â‰  2560ï¼Œè·³è¿‡")
#             continue
        
        # æå–ç´¢å¼•ï¼ˆä»Ž sample_0000.png â†’ 0ï¼‰
        indices = []
        for path in img_paths:
            basename = os.path.basename(path)
            idx = int(basename.split('_')[1].split('.')[0])  # 'sample_0000.png' â†’ 0
            indices.append(idx)
        indices = np.array(indices)
        
#         # æ£€æŸ¥æ˜¯å¦ä¸º 0~1279 çš„æŽ’åˆ—
#         if not (np.sort(indices) == np.arange(2560)).all():
#             print(f"âš ï¸ è­¦å‘Š: ç´¢å¼•ä¸å®Œæ•´æˆ–é‡å¤ï¼Œè·³è¿‡ {snr_folder}/{noise_type}")
#             continue
        
        # æŒ‰ç´¢å¼•å¯¹é½æ ‡ç­¾
        aligned_labels = original_labels[indices]  # shape: (2560,)
        
        # åˆ›å»º dataset å’Œ dataloader
        try:
            val_ds = Mydatasetpro(img_paths, aligned_labels.tolist(), transform)
            val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, drop_last=False)
        except Exception as e:
            print(f"âŒ Dataset åˆ›å»ºå¤±è´¥: {e}")
            continue
        
        # æŽ¨ç†
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for images, labels in val_dl:
                # images: (B, C, H, W), labels: (B,)
                outputs = model(images)
                preds = torch.argmax(outputs, dim=1)
                all_preds.append(preds.cpu().numpy())
                all_targets.append(labels.cpu().numpy())
        
        # åˆå¹¶ç»“æžœ
        y_pred = np.concatenate(all_preds)
        y_true = np.concatenate(all_targets)
        
        # è®¡ç®—å‡†ç¡®çŽ‡
        acc = accuracy_score(y_true, y_pred)
        results_summary[(snr_folder, noise_type)] = acc
        
        print(f"  â†’ Accuracy: {acc:.4f} ({acc*100:.2f}%)")
        print("  â†’ Classification Report:")
        print(classification_report(y_true, y_pred, zero_division=0))

# ========================
# 4. æ‰“å°æ±‡æ€»ç»“æžœ
# ========================
print("\n" + "="*60)
print("ðŸ“Š æœ€ç»ˆå‡†ç¡®çŽ‡æ±‡æ€»:")
print("="*60)
for (snr, noise), acc in sorted(results_summary.items()):
    print(f"{snr:>8} | {noise:<12} | Accuracy: {acc*100:6.2f}%")

# å¯é€‰ï¼šä¿å­˜ä¸º CSV
import pandas as pd
summary_df = pd.DataFrame([
    {'SNR': snr, 'NoiseType': noise, 'Accuracy': acc}
    for (snr, noise), acc in results_summary.items()
])


# In[11]:


summary_df.to_csv("cwt_evaluation_summary-20251223_GLN_spect_p_f_202_fl_22.csv")
print(f"\nâœ… æ±‡æ€»ç»“æžœå·²ä¿å­˜)





